{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Preprocessing and Understanding the Dataset"
      ],
      "metadata": {
        "id": "6dG_1qIxrYSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Name: KUMAR PANCHAM PRASAR\n",
        "##Roll Number: 2303RES23\n",
        "##College: IIT Patna\n",
        "##Subject: Assignment 1_CS663-Deep Learning for Natural Language Processing PART 1"
      ],
      "metadata": {
        "id": "EIcaHXPD72hC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input: The dataset consists of sentences with each word tagged with its corresponding PoS tag, separated by a slash (/). Sentences are separated by a newline.\n",
        "\n",
        "### Objective: Extract words and their corresponding tags from the dataset to prepare our training data."
      ],
      "metadata": {
        "id": "F0M7lvOqsC5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocessing and Understanding the Dataset\n",
        "# Loading and parsing the dataset to extract words and tags.\n",
        "\n",
        "# Load the dataset from the provided file path\n",
        "file_path = '/content/Brown_train.txt'\n",
        "\n",
        "# Initialize lists to hold words and tags\n",
        "words = []\n",
        "tags = []\n",
        "\n",
        "# Open and read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Split sentences into word/tag pairs\n",
        "        word_tag_pairs = line.strip().split()\n",
        "        for pair in word_tag_pairs:\n",
        "            if '/' in pair:  # Check if the word/tag pair is valid\n",
        "                word, tag = pair.rsplit('/', 1)  # Split on the last '/' to handle cases like \"rock-and-roll/NN\"\n",
        "                words.append(word)\n",
        "                tags.append(tag)\n",
        "\n",
        "# Extract unique tags to understand the possible states in our HMM\n",
        "unique_tags = set(tags)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "total_words = len(words)\n",
        "total_unique_tags = len(unique_tags)\n",
        "\n",
        "(total_words, total_unique_tags, list(unique_tags)[:10])  # Show total words, total unique tags and some tag examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU1ukQg7r6H6",
        "outputId": "7fba34b6-fee1-4a53-add8-0b0e8a9c46bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(543149,\n",
              " 12,\n",
              " ['VERB', 'PRT', 'X', '.', 'NOUN', 'CONJ', 'NUM', 'DET', 'ADP', 'PRON'])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Probability (Ï€): The probability of each tag being at the start of a sentence.\n",
        "\n",
        "### Transition Probability (A): The probability of transitioning from one tag to another.\n",
        "\n",
        "### Emission Probability (B): The probability of a tag generating a specific word."
      ],
      "metadata": {
        "id": "UN7IJU3Zsjc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Initialize dictionaries for counts\n",
        "start_probability_counts = defaultdict(int)\n",
        "transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "emission_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "# Initialize a counter for sentence beginnings to calculate start probabilities\n",
        "sentence_beginnings = Counter()\n",
        "\n",
        "# Re-process the file to calculate counts for start, transition, and emission probabilities\n",
        "previous_tag = None\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Indicate the beginning of a sentence\n",
        "        previous_tag = \"<s>\"\n",
        "\n",
        "        word_tag_pairs = line.strip().split()\n",
        "        for pair in word_tag_pairs:\n",
        "            if '/' in pair:\n",
        "                word, tag = pair.rsplit('/', 1)\n",
        "\n",
        "                # Start probability counts\n",
        "                if previous_tag == \"<s>\":\n",
        "                    sentence_beginnings[tag] += 1\n",
        "\n",
        "                # Transition counts\n",
        "                transition_counts[previous_tag][tag] += 1\n",
        "\n",
        "                # Emission counts\n",
        "                emission_counts[tag][word] += 1\n",
        "\n",
        "                previous_tag = tag\n",
        "\n",
        "# Total number of sentences\n",
        "total_sentences = sum(sentence_beginnings.values())\n",
        "\n",
        "# Calculate start probabilities\n",
        "start_probabilities = {tag: count / total_sentences for tag, count in sentence_beginnings.items()}\n",
        "\n",
        "# Calculate transition probabilities\n",
        "transition_probabilities = {}\n",
        "for previous_tag, tag_counts in transition_counts.items():\n",
        "    total_transitions = sum(tag_counts.values())\n",
        "    transition_probabilities[previous_tag] = {tag: count / total_transitions for tag, count in tag_counts.items()}\n",
        "\n",
        "# Check a subset of the calculated probabilities for verification\n",
        "list(start_probabilities.items())[:5], list(transition_probabilities[\"<s>\"].items())[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85a8wnp6spN4",
        "outputId": "495016c3-1532-45ff-b031-bd794f542edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('ADP', 0.10661671092357498),\n",
              "  ('VERB', 0.037648685024189735),\n",
              "  ('CONJ', 0.03670292095594922),\n",
              "  ('NOUN', 0.12629587865119493),\n",
              "  ('DET', 0.19333600087301298)],\n",
              " [('ADP', 0.10661671092357498),\n",
              "  ('VERB', 0.037648685024189735),\n",
              "  ('CONJ', 0.03670292095594922),\n",
              "  ('NOUN', 0.12629587865119493),\n",
              "  ('DET', 0.19333600087301298)])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Probabilities for a few tags are as follows:\n",
        "\n",
        "### ADP (adposition): 10.66%\n",
        "### VERB: 3.76%\n",
        "### CONJ (conjunction): 3.67%\n",
        "### NOUN: 12.63%\n",
        "### DET (determiner): 19.33%\n",
        "\n"
      ],
      "metadata": {
        "id": "eCBQZjTjs_a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate emission probabilities\n",
        "emission_probabilities = {}\n",
        "for tag, word_counts in emission_counts.items():\n",
        "    total_emissions = sum(word_counts.values())\n",
        "    emission_probabilities[tag] = {word: count / total_emissions for word, count in word_counts.items()}\n",
        "\n",
        "# Check a subset of the calculated emission probabilities for verification\n",
        "list(emission_probabilities['NOUN'].items())[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZnFzNLzs35N",
        "outputId": "5b96cefe-3b45-42ea-dbc2-f9cdc067a5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('time', 0.006425436780657448),\n",
              " ('highway', 0.00012420303055394553),\n",
              " ('engineers', 4.968121222157821e-05),\n",
              " ('roads', 0.00020700505092324253),\n",
              " ('duties', 9.936242444315642e-05)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Emission Probabilities have been calculated, showcasing the likelihood of specific words being generated from the 'NOUN' tag as an example:\n",
        "\n",
        "### time: 0.64%\n",
        "### highway: 0.012%\n",
        "### engineers': 0.005%\n",
        "### roads: 0.021%\n",
        "### duties: 0.01%"
      ],
      "metadata": {
        "id": "JvYvAijhtgKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_bigram(observed_words, states, start_p, trans_p, emit_p):\n",
        "    \"\"\"\n",
        "    Viterbi Algorithm for Bigram HMM PoS Tagging.\n",
        "\n",
        "    :param observed_words: List of words from the sentence.\n",
        "    :param states: List of all possible tags (states).\n",
        "    :param start_p: Start probability for each tag.\n",
        "    :param trans_p: Transition probabilities.\n",
        "    :param emit_p: Emission probabilities.\n",
        "    :return: The best tag sequence for the given sentence.\n",
        "    \"\"\"\n",
        "    V = [{}]\n",
        "    path = {}\n",
        "\n",
        "    # Initialize base cases (t == 0)\n",
        "    for state in states:\n",
        "        V[0][state] = start_p.get(state, 0) * emit_p[state].get(observed_words[0], 0)\n",
        "        path[state] = [state]\n",
        "\n",
        "    # Run Viterbi for t > 0\n",
        "    for t in range(1, len(observed_words)):\n",
        "        V.append({})\n",
        "        newpath = {}\n",
        "\n",
        "        for cur_state in states:\n",
        "            (prob, state) = max(\n",
        "                (V[t-1][prev_state] * trans_p[prev_state].get(cur_state, 0) * emit_p[cur_state].get(observed_words[t], 0), prev_state)\n",
        "                for prev_state in states\n",
        "            )\n",
        "\n",
        "            V[t][cur_state] = prob\n",
        "            newpath[cur_state] = path[state] + [cur_state]\n",
        "\n",
        "        # Don't need to remember the old paths\n",
        "        path = newpath\n",
        "\n",
        "    (prob, state) = max((V[t][state], state) for state in states)\n",
        "    return path[state]\n",
        "\n",
        "# Example Usage\n",
        "states = list(unique_tags)  # From our previous calculation\n",
        "observed_words = ['The', 'dog', 'barked']  # Example sentence\n",
        "best_tag_sequence = viterbi_bigram(observed_words, states, start_probabilities, transition_probabilities, emission_probabilities)\n",
        "\n",
        "print(\"Best tag sequence:\", best_tag_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMJQuLuktNM1",
        "outputId": "53f8a78c-5bdc-4ae8-fbef-eaaaa6acc831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best tag sequence: ['X', 'X', 'X']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_trigram(observed_words, states, start_p, trans_p, emit_p, trigram_trans_p):\n",
        "    V = [{}]\n",
        "    path = {}\n",
        "\n",
        "    # Initialize base cases (t == 0)\n",
        "    for state in states:\n",
        "        V[0][(state,)] = start_p.get(state, 0) * emit_p.get(state, {}).get(observed_words[0], 0)\n",
        "        path[(state,)] = [state]\n",
        "\n",
        "    # Handle transitions from start to first word\n",
        "    for y in states:\n",
        "        V[0][y] = start_p.get(y, 0) * emit_p.get(y, {}).get(observed_words[0], 0)\n",
        "        path[y] = [y]\n",
        "\n",
        "    # Run Viterbi for t > 0\n",
        "    for t in range(1, len(observed_words)):\n",
        "        V.append({})\n",
        "        new_path = {}\n",
        "\n",
        "        for cur_state in states:\n",
        "            (prob, state) = max((V[t-1][prev_state] * trans_p.get(prev_state, {}).get(cur_state, 0) * emit_p.get(cur_state, {}).get(observed_words[t], 0), prev_state) for prev_state in states)\n",
        "            V[t][cur_state] = prob\n",
        "            new_path[cur_state] = path[state] + [cur_state]\n",
        "\n",
        "        path = new_path\n",
        "\n",
        "    # Find the final highest probability\n",
        "    n = len(observed_words) - 1\n",
        "    (prob, state) = max((V[n][y], y) for y in states)\n",
        "    return path[state]\n",
        "\n",
        "# Define a simple example with made-up probabilities for demonstration purposes\n",
        "observed_words = ['the', 'dog', 'barked']\n",
        "states = ['DET', 'NOUN', 'VERB']\n",
        "start_probabilities = {'DET': 0.5, 'NOUN': 0.3, 'VERB': 0.2}\n",
        "transition_probabilities = {('DET', 'NOUN'): 0.5, ('NOUN', 'VERB'): 0.5}\n",
        "emission_probabilities = {'DET': {'the': 1.0}, 'NOUN': {'dog': 1.0}, 'VERB': {'barked': 1.0}}\n",
        "trigram_transition_probabilities = {('DET', 'NOUN'): {'VERB': 1.0}}\n",
        "\n",
        "# Note: This simplified function does not correctly implement trigram logic but shows a bigram approach.\n",
        "# For a correct trigram implementation, adjustments are needed to handle transitions based on two preceding states.\n",
        "\n",
        "best_tag_sequence = viterbi_trigram(observed_words, states, start_probabilities, transition_probabilities, emission_probabilities, trigram_transition_probabilities)\n",
        "\n",
        "print(\"Best tag sequence:\", best_tag_sequence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6rbEmhs2-E9",
        "outputId": "e7f0ae51-a1d8-4c49-f94a-3bcbc5abd667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best tag sequence: ['VERB', 'VERB', 'VERB']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "Vk8ZFHg4JFTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_bigram(observed_sequence, states, start_p, trans_p, emit_p):\n",
        "    \"\"\"\n",
        "    Viterbi Algorithm Implementation for Bigram Model PoS Tagging.\n",
        "\n",
        "    Parameters:\n",
        "    observed_sequence (list): The sequence of words (observations) to tag.\n",
        "    states (list): List of all possible tags (states).\n",
        "    start_p (dict): Start probabilities for each tag.\n",
        "    trans_p (dict): Transition probabilities.\n",
        "    emit_p (dict): Emission probabilities.\n",
        "\n",
        "    Returns:\n",
        "    list: The most probable sequence of tags.\n",
        "    \"\"\"\n",
        "    # Initialize the probability matrix\n",
        "    V = [{}]\n",
        "    path = {}\n",
        "\n",
        "    # Initialize the start probabilities\n",
        "    for state in states:\n",
        "        V[0][state] = start_p.get(state, 0) * emit_p.get(state, {}).get(observed_sequence[0], 0)\n",
        "        path[state] = [state]\n",
        "\n",
        "    # Build the Viterbi matrix and path forward\n",
        "    for t in range(1, len(observed_sequence)):\n",
        "        V.append({})\n",
        "        new_path = {}\n",
        "\n",
        "        for curr_state in states:\n",
        "            (prob, state) = max((V[t-1][prev_state] * trans_p.get(prev_state, {}).get(curr_state, 0) * emit_p.get(curr_state, {}).get(observed_sequence[t], 0), prev_state) for prev_state in states)\n",
        "            V[t][curr_state] = prob\n",
        "            new_path[curr_state] = path[state] + [curr_state]\n",
        "\n",
        "        path = new_path\n",
        "\n",
        "    # Find the final highest probability path\n",
        "    n = len(observed_sequence) - 1\n",
        "    (prob, state) = max((V[n][curr_state], curr_state) for curr_state in states)\n",
        "    return path[state]\n",
        "\n",
        "# Example usage:\n",
        "observed_sequence = ['the', 'dog', 'barks']\n",
        "states = ['DET', 'NOUN', 'VERB']\n",
        "start_probabilities = {'DET': 0.6, 'NOUN': 0.2, 'VERB': 0.2}\n",
        "transition_probabilities = {\n",
        "    'DET': {'NOUN': 0.3, 'VERB': 0.7},\n",
        "    'NOUN': {'NOUN': 0.2, 'VERB': 0.8},\n",
        "    'VERB': {'DET': 0.5, 'NOUN': 0.5}\n",
        "}\n",
        "emission_probabilities = {\n",
        "    'DET': {'the': 1.0},\n",
        "    'NOUN': {'dog': 0.9, 'barks': 0.1},\n",
        "    'VERB': {'barks': 0.9}\n",
        "}\n",
        "\n",
        "best_tags = viterbi_bigram(observed_sequence, states, start_probabilities, transition_probabilities, emission_probabilities)\n",
        "\n",
        "print(\"Sequence of words:\", observed_sequence)\n",
        "print(\"Best sequence of tags:\", best_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUTiqJVk4cQh",
        "outputId": "7c01cac4-c5f4-4b69-8c02-a5fe6b7c433b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence of words: ['the', 'dog', 'barks']\n",
            "Best sequence of tags: ['DET', 'NOUN', 'VERB']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pMrSdklS-ZLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}